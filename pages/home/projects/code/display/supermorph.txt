name: superMORPH
image: supermorph>1
image name: #[superMORPH]
white: true
github: https://github.com/v-exec/superMORPH
tags: project, code, display
title: #[superMORPH] is a visual mathmind.
content: #[superMORPH] uses the mathematical superformula to generate 3D supershapes whose parameters are driven through a userâ€™s input using a Kinect.

~[# Superformula
+
+
# Where 'theta' is equal to a given pole in 2D space
+
+
r = (((1 / a) * cos (m1 / 4) * theta) ^ n2 + ((1 / b) * sin (m2 / 4 * theta)) ^ n3) ^ -1 / n1
+
+
# Extended to 3D
+
+
r1 = r where 'theta' is equal to a given longitudinal point
+
r2 = r where 'theta' is equal to a given latitudinal point
+
+
# For each point in 3D space
+
+
x = radius * r1 * cos(longitude point) * r2 * cos(latitude point)
+
y = radius * r1 * sin(longitude point) * r2 * cos(latitude point)
+
z = radius * r2 * sin(latitude point)
]

<iframe class="media" src="https://www.youtube.com/embed/IBONVVaH-2o" frameborder="0" allowfullscreen></iframe>
+
+
I used the Kinect's depth sensor to gather data regarding the user's width, height, distance, and joint coordinates, using a combination of @[KinectPV2>https://github.com/ThomasLengeling/KinectPV2], a library to interface Kinect with Processing(Java), and my own code.

&[supermorph>2]

This data is normalized to reduce the jittery input, and then used to drive the parameters of the superformula, changing the supershape's structure and appearance. Additionally, users can rotate and zoom the camera by closing their hands and dragging.

&[supermorph>1]

This project was a collaborative piece I made with Sarah Lauzon, who managed the majority of the work and coding related to the supershape generation, rendering, and animation, as well as the camera system. I created the algorithms required for reliable user width and height calculaiton using pixel scanning, hand gesturing handling, and parameter and camera control mapping. Simply put, Sarah worked on the output, and I worked on the input.